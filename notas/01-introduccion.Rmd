# Introducción {#introduccion}


## ¿Qué es aprendizaje de máquina (machine learning)? 


```{r, include = FALSE}
library(ggplot2)
theme_set(theme_minimal(base_size = 13))
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Métodos **computacionales** para **aprender de datos**  con el fin
de producir reglas para 
mejorar el **desempeño** en alguna tarea o toma de decisión. 

En este curso nos enfocamos en las tareas de aprendizaje supervisado (predecir o estimar una variable respuesta a partir de datos de entrada) y aprendizaje no supervisado (describir estructuras interesantes en datos,
donde no necesariamente hay una respuesta que predecir).

#### Ejemplos de tareas de aprendizaje: {-}

- Predecir si un cliente de tarjeta de crédito va a caer en impago en los próximos
tres meses.
- Reconocer palabras escritas a mano (OCR).
- Detectar llamados de ballenas en grabaciones de boyas. 
- Estimar el ingreso mensual de un hogar a partir de las características
de la vivienda, posesiones y equipamiento y localización geográfica.
- Dividir a los clientes de Netflix según sus gustos.
- Recomendar artículos a clientes de un programa de lealtad o servicio online.

Las razones usuales para intentar resolver estos problemas **computacionalmente**
son diversas:

- Quisiéramos obtener una respuesta barata, rápida, **automatizada**, y 
con suficiente precisión.
Por ejemplo, reconocer caracteres en una placa de coche de una fotografía se puede hacer por
personas, pero eso es lento y costoso. Igual oír cada segundo de grabación
de las boyas para saber si hay ballenas o no. Hacer mediciones directas
del ingreso de un hogar requiere mucho tiempo y esfuerzo.
- Quisiéramos **superar el desempeño actual** de los expertos o de reglas simples utilizando
datos: por ejemplo, en la decisión de dar o no un préstamo a un solicitante,
puede ser posible tomar mejores decisiones con algoritmos que con evaluaciones personales
o con reglas simples que toman en cuenta el ingreso mensual, por ejemplo.
- Al resolver estos problemas computacionalmente tenemos
oportunidad de aprender más del problema que nos interesa: estas
soluciones forman parte de un ciclo de **análisis de datos** donde podemos 
aprender de una forma más concentrada cuáles son
características y patrones importantes de nuestros datos.


Es posible aproximarse a todos estos problemas usando reglas (por ejemplo,
si los pixeles del centro de la imagen están vacíos, entonces es un cero, 
si el crédito total es mayor al 50\% del ingreso anual, declinar el préstamo, etc). Las razones para no tomar un enfoque de reglas
 construidas "a mano":

- Cuando conjuntos de reglas creadas a mano se desempeñan mal (por ejemplo, para otorgar créditos, reconocer caracteres, etc.)
- Reglas creadas a mano pueden ser difíciles de mantener (por ejemplo, un corrector
ortográfico), pues para problemas interesantes muchas veces se requieren grandes
cantidades de reglas.


## Ejemplo: reglas y aprendizaje

Lectura de un medidor mediante imágenes. Supongamos que en
una infraestructura donde hay medidores análogos (de electricidad, gas, etc.) que no se comunican. ¿Podríamos pensar en utilizar
fotos tomadas automáticamente para medir el consumo?

Por ejemplo, consideramos el siguiente problema (tomado de [este sitio](http://raphael.candelier.fr/?blog=Image%20Moments)):

```{r, message = FALSE}
library(imager)
library(tidyverse)
# Datos: http://raphael.candelier.fr/?blog=Image%20Moments
medidor_vid <- load.video("figuras/gauge_raw.mp4", fps = 5)
```



Nótese que las imágenes y videos son matrices o arreglos de valores de pixeles, por ejemplo
estas son las dimensiones para el video y para un cuadro:
```{r}
dim(medidor_vid)
medidor <- frame(medidor_vid, 20)
dim(medidor)
```

En este caso, el video tienen 350 cuadros, y existen tres canales. 
Cada canal está representado por una matriz de 370x336 valores,
y en cada uno está un valor que representa la intensidad del pixel.

Buscámos hacer cálculos con estas matrices para extraer la información
que queremos. En este caso, construiremos estos cálculos a mano.

Primero filtramos (extraemos canal rojo, difuminamos y
aplicamos un umbral):

```{r}
medidor_1 <- medidor %>% R %>% isoblur(10)
aguja <-  medidor_1 %>% threshold("99%") 
layout(t(1:3))
par(mar = c(2, 2, 2, 2))
plot(medidor, axes = FALSE)
plot(medidor_1, axes = FALSE)
plot(aguja, axes = FALSE)
```

Logramos extraer la aguja, aunque hay algo de ruido adicional.
Podemos extraer las líneas que pasan por más pixeles
encendidos (transformada de Hough). Con estas líneas tenemos
calculada la orientación de la aguja:

```{r, message=FALSE}
lineas_h <- hough_line(aguja, ntheta = 500, data.frame=T)
lineas_top <- lineas_h %>% 
    arrange(desc(score)) %>% 
    top_n(5) %>% 
    select(-score)  
lineas_top
layout(matrix(1:4, 2))
par(mar = c(2, 2, 2, 2))
plot(medidor, axes = FALSE)
plot(medidor_1, axes = FALSE)
plot(aguja, axes = FALSE)
plot(aguja, axes = FALSE)
pwalk(lineas_top, nfline, col="red")
```

Y ahora podemos aplicar el proceso de arriba
a todas la imágenes:

```{r, fig.width=6, fig.height = 4, out.width = "400px"}
seleccionar_lineas <- function(lineas){
    lineas %>% 
      arrange(desc(score)) %>% 
      filter(rho > 0) %>% 
      top_n(5, score) %>% 
      select(-score) %>% 
      summarise(theta = 180*mean(theta)/pi) %>% 
      pull(theta)
}

# procesar por cuadro
num_cuadros <- dim(medidor_vid)[3]

angulos <- 1:num_cuadros %>% 
    map( ~frame(medidor_vid, .x)) %>% 
    map(R) %>% map( ~ isoblur(.x, 10)) %>% 
    map( ~ threshold(.x, "98%")) %>% 
    map( ~ hough_line(.x, 100, data.frame = TRUE)) %>% 
    map_dbl(seleccionar_lineas)

angulos_tbl <- tibble(t = 1:num_cuadros, angulo = angulos)
```

```{r, eval = FALSE}
# puedes usar este código para crear un gif animado:
library(gganimate)
ggplot(angulos_tbl, aes(x = t, y = angulo)) +
    geom_line() +
    transition_reveal(t) +
    transition_time(0.5)
```



![](https://media.giphy.com/media/S4HVNskqDGOADaeOY2/giphy.gif){width=150px}
![](https://media.giphy.com/media/hVm56lMsCDLHSsSOH0/giphy.gif){width=400px}


---

Por el contrario, en el **enfoque de aprendizaje**, comenzamos con un conjunto de datos etiquetado
(por una persona, por un método costoso, etc.), y utilizamos alguna
estructura general para aprender a producir la respuesta a partir
de las imágenes. Por ejemplo, en este caso podríamos usar regresión
lineal (regularizada) sobre los valores de los pixeles de la imagen:

```{r}
library(keras)
# usamos los tres canales de la imagen
x <- as.array(medidor_vid) %>% aperm(c(3,1,2,4))

# reordenamos
set.seed(1234)
orden <- sample(1:num_cuadros, num_cuadros)
x <- x[orden,,,,drop=FALSE]
y <- angulos[orden]
```


```{r}
modelo_aguja <- keras_model_sequential() %>%
    layer_flatten() %>% 
    layer_dropout(rate = 0.95) %>% 
    layer_dense(units = 1, activation = 'linear')
```
Ajustamos el modelo:

```{r, message = FALSE}
modelo_aguja %>% compile(
  loss = loss_mean_absolute_error,
  optimizer = optimizer_sgd(lr = 0.01, decay = 0.001),
  metrics = c('mean_absolute_error')
)
# Entrenar
modelo_aguja %>% fit(
  x, y,
  batch_size = 20,
  epochs = 200,
  validation_split = 0.25
)

```

Y observamos que obtenemos predicciones prometedoras:

```{r, out.width = '500px', fig.width = 6, fig.height = 4,}
preds <- predict(modelo_aguja, x)
qplot(y, preds, alpha =0.5) + geom_abline(slope = 1, intercept = 0, col = 'red')
```

De forma que podemos resolver este problema con algoritmos generales,
como regresión, sin tener que aplicar métodos sofisticados de
procesamiento de imágenes. El enfoque de aprendizaje es particularmente
efectivo cuando hay cantidades grandes de datos poco ruidosos, y aunque
en este ejemplo los dos enfoques dan resultados razonables, 
en procesamiento de imágenes es cada vez más común usar redes neuronales
grandes para resolver este tipo de problemas.


## Ejemplo:  mediciones costosas

Consideramos la medición de ingreso total trimestral para los
hogares de la encuesta ENIGH. Cada una de estas mediciones
es muy costosa en tiempo y dinero. Sin embargo, hay otras características
de los hogares que podemos medir.

Por ejemplo, consideremos una muestra de la ENIGH 2010:

```{r, message = FALSE, warning = FALSE}
dat_ingreso <- read_csv(file = '../datos/enigh-ejemplo.csv') %>% 
  mutate(num_focos = FOCOS) %>%
  mutate(ingreso_miles = round(INGCOR / 1000)) %>% 
  #mutate(marginación = recode(marginación, Alto = "Alto", `Muy alto`= "Muy Alto",
  #    Medio = "Medio", Bajo = "Medio", `Muy bajo`="Bajo")) %>% 
  mutate(tel_celular = ifelse(SERV_2 == 1, "Sí", "No")) %>% 
  mutate(marginación = fct_reorder(marginación, ingreso_miles, median)) %>% 
  rename(ocupadas = PEROCU)

sample_n(dat_ingreso, 10) %>% 
    select(entidad = NOM_ENT..307, num_focos, marginación, 
           tel_celular, ocupadas, ingreso_miles)  %>%
    arrange(desc(ingreso_miles)) %>% 
    knitr::kable()
```

```{r, fig.width=5, fig.asp=0.7}
print("Percentiles de ingreso (miles de pesos)")
quantile(dat_ingreso$ingreso_miles, probs= c(0.05, 0.10,0.5,0.9, 0.95)) %>% round(2)
```

Quizá podemos usar otras variables más fácilmente medibles
para predecir el ingreso de un hogar. Por ejemplo, podríamos
considerar variables de entorno (marginación del municipio),
del hogar (si tienen celular), y de las personas dentro del
hogar (número de personas ocupadas):

```{r, message = FALSE, warning = FALSE, fig.width = 9, fig.asp = 0.3}
ggplot(dat_ingreso, 
       aes(x = ocupadas, y = ingreso_miles, colour= tel_celular)) + 
  geom_jitter(width=0.5, height = 0.3, size = 1, alpha = 0.5) +
  scale_y_log10(breaks = c(2.5, 5, 10, 20, 40, 80, 160, 320), 
                limits = c(2.5, 360)) +
    ylab("Ingreso trimestral \n (miles de pesos)") +
  facet_wrap( ~marginación, nrow=1) + 
  geom_smooth(span = 5, method = "loess", method.args = list(degree=1)) +
  xlab("Personas ocupadas")
```


```{r, fig.width = 9, fig.asp = 0.3, message = FALSE, warning = FALSE}
ggplot(dat_ingreso, 
       aes(x = num_focos, y = (0.1 + ingreso_miles) / (TOT_RESI - MENORES), colour = tel_celular)) + 
  geom_jitter(width=0.5, size=1, alpha = 0.5) +
  scale_y_log10(breaks = c(2.5, 5, 10, 20, 40, 80), limits = c(1.5, 100)) +
    ylab("Ingreso trimestral por adulto \n (miles de pesos)") +
  facet_wrap( ~marginación, nrow=1) + 
  geom_smooth(span = 5, method = "loess", method.args = list(degree=1, family = "symmetric")) +
  xlab("Número de focos") + xlim(c(0,25))
```

Estas variables son relevantes, y vemos que explican una parte considerable
de la variación de los ingresos de los hogares. Sin embargo,
¿cómo podemos mejorar nuestras predicciones para el estrato de marginación
muy alta, donde hay relativamente pocos datos, o para aquellos hogares
con alto número de focos? Parece ser necesario incluír
más variables, pero un enfoque ingenuo puede no dar muy buenas predicciones.


- En algunas encuestas se pregunta directamente el ingreso mensual del hogar. La
respuesta es generalmente una mala estimación del verdadero ingreso, por lo que
actualmente se prefiere utilizar aprendizaje para estimar a partir de otras
variables que son más fielmente reportadas por encuestados (años de estudio,
ocupación, número de focos en el hogar, etc.)




## Supervisado y no supervisado

Las tareas de aprendizaje se dividen en dos grandes partes: aprendizaje
supervisado y aprendizaje no supervisado.


- **Aprendizaje supervisado** Construir un modelo o algoritmo para
predecir o estimar un *target* o una *variable de salida* a partir
de ciertas variables de entrada.

Predecir y estimar, en este contexto, se refieren a cosas similares. Generalmente
se usa
*predecir* cuando se trata de variables que no son observables ahora, sino en el futuro,
y 
*estimar* cuando nos interesan variables actuales que no podemos observar ahora
por costos o por la naturaleza del fenómeno.


Por ejemplo, para identificar a los clientes con alto riesgo de impago
de tarjeta de crédito, utilizamos datos históricos de clientes que han pagado
y no han pagado. Con estos datos entrenamos un algoritmo para detectar anticipadamente los
clientes con alto riesgo de impago.

Usualmente dividimos los problemas de aprendizaje supervisado en dos tipos,
dependiendo de la variables salida:

- Problemas de **regresión**: cuando la salida es una variable numérica. El ejemplo
de estimación de ingreso es un problema de regresión
- Problemas de **clasificación**: cuando la salida es una variable categórica. El
ejemplo de detección de dígitos escritos a manos es un problema de clasificación.

#### Aprendizaje no supervisado {-}

-  **Aprendizaje no supervisado** En este caso no hay *target*
o variable salida. Buscamos modelar y entender las relaciones entre variables
y entre observaciones, o patrones importantes o interesantes en los datos.

Los problemas supervisados tienen un objetivo claro: hacer las mejores
predicciones posibles bajo ciertas restricciones. Los problemas no supervisados
tienden a tener objetivos más vagos, y por lo mismo pueden ser más difíciles.



## Aprendizaje Supervisado

Por el momento nos concentramos en problemas supervisados de regresión, es
decir predicción de variables numéricas.

¿Cómo entendemos el problema de predicción?

### Proceso generador de datos (modelo teórico) {-}

Pensaremos en términos
de **modelos probabilísticos que generan los datos**. La idea es que
estos representan los procesos que generan los datos o las observaciones.

Si $Y$ es la respuesta
que queremos predecir, y $X$ es una entrada que queremos usar para predecir
$Y$,  
consideramos que las variables aleatorias $Y$ y $X$ están relacionadas como sigue:
$$Y=f(X)+\epsilon,$$
donde $\epsilon$ es una término de error aleatorio 
que tiene valor esperado $\textrm{E}(\epsilon | X)=0$ (su media no depende
de los valores de las entradas).


- $f$ expresa la relación sistemática que hay entre $Y$ y $X$: para cada valor
posible de $X$, la *contribución* de $X$ a $Y$ es $f(X)$. Típicamente
es una función complicada de $X$.
- Pero $X$ **no determina** a $Y$, como en el ejemplo anterior de rendimiento
de coches.
Entonces agregamos una error aleatorio $\epsilon$, con media cero (si la media
no es cero podemos agregar una constante a $f$).
- $\epsilon$ representa, por ejemplo, el efecto de variables que no hemos
medido o  procesos aleatorios que determinan la respuesta.



#### Ejemplo {-}

Vamos a usar simulación para entender estas ideas: supongamos que $X$
es el número de años de estudio de una persona y $Y$ es su ingreso mensual.
En primer lugar, estas son el número de años de estudio de 8 personas:

```{r, fig.width=5, fig.asp=0.7}
x <- c(1,7,10,0,0,5,9,13,2,4,17,18,1,2)
```

Ahora *supondremos* que la dependencia de Y de X está dada por
$Y=f(X)+\epsilon$ por una función $f$ que no conocemos (esta función está
determinada por el fenómeno)
```{r}
f <- function(x){
  ifelse(x < 10, 1000*sqrt(x), 1000*sqrt(10))
}
```

El ingreso no se determina
únicamente por número de años de estudio. Suponemos entonces que hay algunas 
variables
adicionales que perturban los niveles de $f(X)$ por una cantidad aleatoria. Los
valores que observamos de $Y$ están dados entonces por $Y=f(X)+\epsilon$.

Entonces podríamos obtener, por ejemplo:
```{r, fig.width=5, fig.asp=0.7}
x_g <- seq(0,20,0.5)
y_g <- f(x_g)
dat_g <- data.frame(x = x_g, y = y_g)
set.seed(281)
error <- rnorm(length(x), 0, 500)
y <- f(x) + error
datos <- tibble(x = x, y = y)
datos$y_media <- f(datos$x)
ggplot(datos, aes(x = x, y = y)) + geom_point() +
  geom_line(data=dat_g, colour = 'blue', size = 1.1) +
  geom_segment(aes(x = x, xend = x, y = y, yend = y_media), col='red')
```


En problemas de aprendizaje nunca conocemos esta $f$ verdadera,
aunque quizá sabemos algo acerca de sus propiedades (por ejemplo, continua, de 
variación suave). Lo que tenemos son los datos, que también podrían haber resultado
en (para otra muestra de personas, por ejemplo):

```{r, fig.width=5, fig.asp=0.7}
set.seed(28015)
error <- rnorm(length(x), 0, 500)
y <- f(x) + error
datos <- data.frame(x = x, y = y)
ggplot(datos, aes(x = x, y = y)) + geom_point() 
```

La siguiente observación nos da una idea de lo que intentamos hacer, aunque
todavía es vaga y requiere refinamiento:

```{block, type='comentario'}
Bajo los supuestos del modelo $Y=f(X)+\epsilon$, **aprender de los datos**
significa intentar recuperar o estimar la forma de la función $f$ que no conocemos.
$f$ representa la relación sistemática entre $Y$ y $X$.
```

¿Qué tan bien podemos estimar esa $f$ que no conocemos, con
los datos disponibles? ¿Qué significa *estimar bien*?
Incluso este ejemplo tan simple muestra las dificultades que vamos a
enfrentar, y la importancia de determinar con cuidado qué tanta información
tenemos, y qué tan buenas pueden ser nuestras predicciones.

### Predicciones {-}

La idea es entonces producir una estimación de f que nos permita hacer predicciones.

Si denotamos por $\hat{f}$ a una estimación de $f$ construida a partir de los datos,
podemos hacer predicciones aplicando $\hat{f}$ a valores de $X$.
La predicción de Y la denotamos por $\hat{Y}$, y $$\hat{Y}=\hat{f}(X).$$
El error de predicción (residual) está dado por el valor observado menos la predicción:
$$Y-\hat{Y}.$$


En nuestro ejemplo anterior, podríamos construir, por ejemplo, una recta
ajustada por mínimos cuadrados:

```{r}
curva_1 <- geom_smooth(data=datos,
  method = "lm", se=FALSE, color="red", formula = y ~ x, size = 1.1)
```

```{r, fig.width=5, fig.asp=0.7}
ggplot(datos, aes(x = x, y = y)) + geom_point() + curva_1
```

En este caso $\hat{f}$  es una recta, y la podemos usar para hacer predicciones.
Por ejemplo, si tenemos una observación con
$x_0=8$ años de estudio, nuestra predicción del ingreso 
$\hat{y}=\hat{f}(8)$ sería

```{r}
lineal <- lm(y ~ x,data = datos)
pred_1 <- predict(lineal, newdata = data.frame(x=8))
pred_1
```

```{r, fig.width=5, fig.asp=0.7}
ggplot(datos, aes(x = x, y = y)) + geom_point() + curva_1 +
  geom_segment(x = 0, xend = 8, y = pred_1, yend = pred_1, colour = 'salmon') +
  geom_segment(x = 8, xend = 8, y = 0, yend = pred_1, colour = 'salmon') +
  annotate('text', x = 0.5, y = pred_1 + 100, label = round(pred_1, 1)) +
  geom_point( x= 8, y =3200, col='green', size = 4)
```

Si observamos que para esta observación con $x_0=8$, resulta que 
el correspondiente ingreso es $y_0=3200$, entonces el error sería
```{r}
y_0 <- 3200
y_0 - pred_1
```


```{block, type='comentario'}
En aprendizaje buscamos que estos errores sean lo más cercano a cero que
sea posible.
```

## Tarea de aprendizaje supervisado {#aprendizaje}

El elemento faltante para definir la tarea de aprendizaje supervisado es 
cuantificar qué significa aproximar *bien* a $f$, o tener predicciones precisas. Para
esto definimos una **función de pérdida**:

$$L(Y, \hat{f}(X)),$$

que nos dice cuánto nos cuesta hacer la predicción $\hat{f}(X)$ cuando el
verdadero valor es $Y$ y las variables de entrada son $X$. 
Una opción conveniente para problemas de regresión
es la **pérdida cuadrática**:

$$L(Y, \hat{f}(X)) =  (Y - \hat{f}(X))^2$$
Esta es una cantidad aleatoria, de modo que en algunos casos este error
puede ser más grande o más chico, aún para la misma predicción. 
Usualmente buscamos una $\hat{f}$ de modo que el error promedio sea chico:

$$Err = E (Y - \hat{f}(X))^2 $$

**Notas**:

- Este valor esperado es sobre la población para la que queremos hacer
predicciones. Es una cantidad teórica, no podemos calcularla con ningún
conjunto de datos.
- Intenta demostrar que bajo error cuadrático medio y suponiendo
el modelo aditivo $Y=f(X)+\epsilon$, el mejor predictor
de $Y$ es $f(x)= E[Y|X=x]$. Es decir: lo que nos interesa es aproximar
lo mejor que se pueda la esperanza condicional

---

Ahora tenemos los elementos para definir con precisión el problema
de aprendizaje supervisado. 

Consideramos un proceso generador de datos $(X,Y)$. 

En primer lugar,
tenemos datos de los que vamos a aprender. Supongamos entonces que tenemos un conjunto de datos *etiquetados* (generados según $(X,Y)$)

$${\mathcal L}=\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \ldots, (x^{(N)}, y^{(N)}) \}$$
que llamamos **conjunto de entrenamiento**. Nótese que usamos minúsculas
para denotar observaciones particulares de $(X,Y)$.

Un **algoritmo de aprendizaje** (**aprender** de los datos)
es una regla que asigna a cada conjunto de
entrenamiento ${\mathcal L}$ una función $\hat{f}$:

$${\mathcal L} \to \hat{f}.$$

Una vez que construimos la función $\hat{f}$, podemos hacer predicciones.
El desempeño del predictor particular $\hat{f}$ se mide como sigue: si
en el futuro observamos otra muestra ${\mathcal T}$, que llamamos **muestra de prueba**,

$${\mathcal T}=\{ (x_0^{(1)},y_0^{(1)}),(x_0^{(2)},y_0^{(2)}), \ldots, (x_0^{(m)}, y_0^{(m)}) \}$$

entonces decimos que el **error de predicción** (cuadrático) de $\hat{f}$ para el
ejemplo $(x_0^{(j)},y_0^{(j)})$ está dado por
$$(y_0^{(j)} - \hat{f}(x_0^{(j)}))^2$$

y el error promedio sobre la muestra ${\mathcal T}$ es

$$\hat{Err} =   \frac{1}{m}\sum_{j=1}^m (y_0^{(j)} - \hat{f}(x_0^{(j)}))^2$$

que es una estimación del error de predicción 
$$Err = E (Y - \hat{f}(X))^2 $$

Adicionalmente, definimos otra cantidad de menor interés,
el **error de entrenamiento**, como 

$$\overline{err} = \frac{1}{N}\sum_{i=1}^N (y^{(i)} - \hat{f}(x^{(i)}))^2.$$

```{block2, type='comentario'}
En aprendizaje supervisado,

- Usando datos de entrenamiento ${\mathcal L}$, construimos una funcion $\hat{f}$ para predecir
- Si observamos nuevos valores $x_0$, nuestra predicción es $\hat{y} = \hat{f}(x_0)$.
- Buscamos que cuando observemos nuevos casos para predecir, nuestro error de predicción
sea bajo en promedio ($Err$ sea bajo)
- Usualmente estimamos $Err$ mediante una muestra de prueba o validación ${\mathcal T}$, así
que buscamos minimizar la estimación $\hat{Err}$

```


El punto más importante que discutiremos ahora es el siguiente:

- Nótese que el error de entrenamiento se calcula sobre la muestra ${\mathcal L}$
que se usó
para construir $\hat{f}$, mientras que el error de predicción se estima usando
una muestra independiente ${\mathcal T}$.
- $\hat{Err}$ es una estimación razonable de el error de predicción $Err$ 
(por ejemplo, $\hat{Err} \to Err$ cuando el tamaño de la muestra de prueba
crece), pero $\overline{err}$ típicamente es una estimación mala del error de
predicción.

#### Ejemplo {-}

En el ejemplo que hemos estado usando, ¿que curva preferirías para
predecir, la gris, la roja o la azul? ¿Cuál tiene menor error de entrenamiento?

```{r, fig.width=5, fig.asp=0.7}
set.seed(280572)
error <- rnorm(length(x), 0, 500)
y <- f(x) + error
datos_entrena <- data.frame(x=x, y=y)
head(datos_entrena)
curva_1 <- geom_smooth(data=datos_entrena,
  method = "loess", se=FALSE, color="gray", span=1, size=1.1)
curva_2 <- geom_smooth(data=datos_entrena,
  method = "loess", se=FALSE, color="red", span=0.5, size=1.1)
curva_3 <- geom_smooth(data=datos_entrena,
  method = "lm", se=FALSE, color="blue", size=1.1)
```

```{r, fig.width=5, fig.asp=0.7, warning = FALSE}
ggplot(datos_entrena, aes(x=x, y=y)) + geom_point() + 
    curva_1 + curva_2 + curva_3
```


Calculamos los errores de entrenamiento de cada curva:

```{r, warning = FALSE}
mod_rojo <- loess(y ~ x, data = datos_entrena, span=0.3)
mod_gris <- loess(y ~ x, data = datos_entrena, span=1)
mod_recta <- lm(y ~ x, data = datos_entrena)
df_mods <- tibble(nombre = c('recta', 'rojo','gris'))
df_mods$modelo <- list(mod_recta, mod_rojo, mod_gris)
```

```{r}
error_f <- function(df, mod){
  function(mod){
    preds <- predict(mod, newdata = df)
    round(sqrt(mean((preds - df$y) ^ 2)))
  }
}
error_ent <- error_f(datos_entrena)

df_mods <- df_mods %>% 
  mutate(error_entrena = map_dbl(modelo, error_ent))
df_mods
```

El error de entrenamiento es considerablemente menor para la curva
roja, y es más grande para la recta.

Sin embargo, consideremos que tenemos una nueva muestra (de prueba).

```{r, fig.width=5, fig.asp=0.7}
set.seed(218052272)
x_0 <- sample(0:13, 100, replace = T)
error <- rnorm(length(x_0), 0, 500)
y_0 <- f(x_0) + error
datos_prueba <- tibble(x = x_0, y = y_0)
datos_prueba
```

```{r}
error_p <- error_f(datos_prueba)
df_mods <- df_mods %>% 
  mutate(error_prueba = map_dbl(modelo, error_p))
df_mods
```

y el error de prueba más bajo está dado por la curva gris.

**Observaciones**

- El "mejor"" modelo en entrenamiento es uno que *sobreajusta* a los datos, pero es
el peor con una muestra de prueba. La curva roja aprende de la componente
de ruido del modelo - lo cual realmente no es aprendizaje.

- El modelo de la recta no es bueno en entrenamiento ni en prueba. Este modelo
no tiene la capacidad para aprender de la señal en los datos.

- El mejor modelo en la muestra de prueba es uno que está entre la recta y
la curva roja en términos de flexibilidad. 

- Nuestra intuición para escoger el modelo gris desde el principio se refleja
en que *generaliza* mejor que los otros, y eso a su vez se refleja en
un error de prueba más bajo.

- ¿De dónde
provienen los errores en la predicción? ¿Podemos hacer el error igual a cero?
Si establemos que el error es una función
creciente de $Y-\hat{Y}$, vemos que
$$ Y-\hat{Y} = f(X) + \epsilon - \hat{f}(X)= (f(X) - \hat{f}(X)) + \epsilon,$$
donde vemos que hay dos componentes que pueden hacer grande a $Y-\hat{Y}$:
    - La diferencia $f(X) - \hat{f}(X)$ está asociada a **error reducible**, pues
depende de qué tan bien estimemos $f(X)$ con $\hat{f}(X)$
    - El error aleatorio $\epsilon$, asociado a  **error irreducible**.

- Cualquiera de estas dos cantidades pueden hacer que nuestras predicciones no sean
precisas. No podemos hacer mucho acerca del error irreducible (sin cambiar las variables
que usamos, la definición del problema, etc.) En nuestro ejemplo anterior, el error reducible:
    - Es grande para el modelo rojo, pues responde demasiado fuerte a ruido en los datos (tiene varianza alta).
    - Es grande para el modelo de la recta, pues no tiene capacidad para acercarse a
la verdadera curva (está sesgado).



## Balance de complejidad y rigidez {#error}

Como vimos en el ejemplo de arriba, el error de entrenamiento no es
un buen indicador del desempeño futuro de nuestras predicciones. Para evaluar
este desempeño, necesitamos una muestra de prueba independiente de la
muestra que usamos para aprender o para entrenar el modelo.

Intuitivamente esto tiene sentido: en el proceso de aprendizaje tenemos
disponibles las etiquetas (sabemos las respuestas), de modo que puede suceder
que el algoritmo **memorice** la asociación de qué etiquetas $y^{(i)}$ van con cada
conjunto de entradas $x^{(i)}$. Esto se dice de varias maneras, por ejemplo:

- El modelo *sobreajusta* a los datos: esto quiere decir que por ajustar aspectos
de los datos de entrenamiento demasiado fuertemente, el algoritmo parece replicar
de cerca los datos de entrenamiento pero se desempeña mal en la predicción.

- El modelo *aprende del ruido*: nuestro proceso de aprendizaje captura aspectos
irrelevantes de los datos, que nuevos datos no van a compartir.

- El modelo *no tiene capacidad de generalización*, porque captura aspectos
que solo están presentes en nuestra muestra de entrenamiento.

- El modelo *tiene varianza alta*, porque cambia mucho dependiendo de la muestra 
de entrenamiento.

- El modelo es *demasiado complejo o flexible* y fácilmente se adapta a cualquier
conjunto de datos, tanto señal como ruido.

En el ejemplo de arriba, también vimos que algunos modelos pueden tener desempeño
malo porque no tienen la capacidad de aprender de patrones reales y generales
en los datos (la recta en el ejemplo anterior). Podemos decir esto de varias maneras:

- El modelo *subajusta* a los datos: no tienen la capacidad de ajustar
aspectos de los datos de entrenamiento que son relaciones reales entre las
variables. 

- El modelo *ignora señal en los datos*: el algoritmo no captura aspectos relevantes de los
datos, que comparten con nuevos datos y pueden utilizarse para hacer predicciones.

- El modelo *no tiene capacidad de aprendizaje*, pues no puede capturar
aspectos que son generales para el fenómeno de interés.

- El modelo tiene *sesgo alto*, porque no puede ajustar patrones generalizables
en los datos.

- El modelo es *demasiado rígido*, y no puede adaptarse ni siquiera a patrones
fuertes y claros en los datos.

Logramos buenas predicciones cuando refinamos nuestros modelos o algoritmos
para lograr *aprender de la señal* e 
*ignorar el ruido, que no ayuda en la predicción*, y lograr reducir el
error de predicción lo más posible con los datos disponibles. Esto requiere
buscar el nivel adecuado de complejidad en los modelos o algoritmos para los
datos que tenemos.

```{block, type='comentario'}
Para construir buenos predictores, requerimos que:

- El algoritmo tenga la **flexibilidad** necesaria para capturar patrones generales y
fuertes en los datos
- El algoritmo tenga la **rigidez** necesaria para tener robustez a patrones de ruido
o particularidades no repetibles de nuestra muestra de entrenamiento.
- Saber intuitivamente cuál es el grado adecuado de complejidad para un problema
dado es difícil. Para decidirlo, evaluamos el desempeño de nuestros métodos
usando una **muestra de prueba**. El nivel adecuado de complejidad se traduce
en menos error de predicción.
```

#### Discusión (error de entrenamiento y prueba)

En términos teóricos, podemos ver cuál es el problema de intentar evaluar el
error de predicción utilizando la muestra de entrenamiento. 

En primer lugar consideremos evaluar el error de predicción para
un ejemplo $$(y_0- \hat{f}(x_0))^2$$
donde $(x_0, y_0)$ es independiente de la muestra de entrenamiento. En este
caso, la $\hat{f}$ está fija, y el valor esperado (error de predicción) nos
da el error de predicción.

Sin embargo, si $(x,y)$ es un caso de entrenamiento, el valor esperado
de 
$$(y- \hat{f}(x))^2$$
requiere un cálculo más complicado, pues ¡ $\hat{f}$ también depende de $(x,y)$,
pues se construye con la muestra de entrenamiento !
Esta cantidad podría ser igual a cero para cualquier $(x,y)$, por ejemplo 
(si nuestro algoritmo "interpola" como el en la curva roja del ejemplo anterior),
y no necesariamente tiene qué ver con el error de predicción.

- En general, el error de entrenamiento es una cantidad secundaria, que 
utilizaremos más como medida de diagnóstico de nuestro proceso de ajuste. La
cantidad que realmente queremos hacer chica es el error de predicción, que evaluamos
con una muestra de prueba independiente de la muestra de entrenamiento.
- Para modelos muy simples, el error de entrenamiento puedes ser similar al de prueba. Sin
embargo, conforme aumentamos complejidad (necesario para capturar patrones reales
en los datos), estos dos errores típicamente divergen.

## ¿Cómo estimar f? 

Ahora mostramos otro aspecto característico del aprendizaje supervisado. En primer
lugar, el método general más usual para encontrar $\hat{f}$ es hacer lo siguiente:

- Consideramos una familia de funciones $h$ candidatas para aproximar $f$
- Calculamos el error de entrenamiento de cada posible $h$, y encontramos
la $h$ que minimiza el error de entrenamiento (la que más se ajusta a los datos
de entrenamiento). Tomamos $\hat{f} = h$.
$$\hat{f} = \min_h \frac{1}{N}\sum_{i=1}^N (y^{(i)} - h(x^{(i)}))^2.$$
- Evaluar el error de predicción del modelo que seleccionamos (queremos que sea bajo):

$$\hat{Err} =   \frac{1}{m}\sum_{j=1}^m (y_0^{(j)} - \hat{f}(x_0^{(j)}))^2$$

De modo que el proceso es un problema de minimización. Lo que hace
interesante nuestro caso es que realmente **no queremos minimizar el error de entrenamiento**. Queremos **minimizar el error de prueba**. O sea que minimizamos una cantidad
que realmente no nos interesa (error de entrenamiento) con la esperanza de minimizar 
la cantidad
que nos interesa (error de predicción).

Como es de esperarse, este esquema simple no funciona muy bien sin afinar
algunos aspectos. Para que la solución anterior sea razonable o buena:

- Tenemos que ser cuidadosos y poder regular la elección de la familia inicial de funciones
(rectas? curvas muy flexibles? etc.). Buscamos familias que tengan
la estructura adecuada para cada problema.
- A veces tenemos que modificar el objetivo del problema de minimización para 
que nos obligue encontrar un balance adecuado de complejidad y error de 
predicción bajo. Por ejemplo, penalizar el objetivo 
de modelos que son poco creíbles o demasiado complicados.
- Perturbar la muestra de entrenamiento de distintas maneras para evitar que
un algoritmo aprenda información irrelevante.

La mayor parte del curso se concentra en considerar qué familias o modelos podemos
utilizar en distintos casos, qué modificaciones de la función objetivo pueden hacerse para
mejorar el proceso de entrenamiento,
y qué perturbaciones de los datos pueden considerarse para mejorar el desempeño predictivo de
nuestros modelos.

## Resumen

- Aprendizaje de máquina: algoritmos que aprenden de los datos para predecir cantidades
numéricas, o clasificar (aprendizaje supervisado), o para encontrar estructura en los
datos (aprendizaje no supervisado).

- En aprendizaje supervisado, el esquema general es: 
  - Un algoritmo aprende de una
muestra de entrenamiento ${\mathcal L}$, que es generada por el proceso generador de datos que nos interesa. Eso quiere decir que produce una función $\hat{f}$ (a partir de ${\mathcal L}$) que nos sirve para hacer predicciones $x \to \hat{f}(x)$ de $y$
  - El error de predicción del algoritmo es $Err$, que mide en promedio qué tan lejos están las predicciones de valores reales.
  - Para estimar esta cantidad usamos una muestra de prueba ${\mathcal T}$, que
  es independiente de ${\mathcal L}$.
  - Esta es porque nos interesa el desempeño futuro de $\hat{f}$ para nuevos casos
  que el algoritmo no ha visto (esto es aprender).
  
- El error en la muestra de entrenamiento no necesariamente es buen indicador
del desempeño futuro de nuestro algoritmo.

- Para obtener las mejores predicciones posibles, es necesario que el algoritmo
sea capaz de capturar patrones en los datos, pero no tanto que tienda a absorber ruido
en la estimación - es un balance de complejidad y rigidez. En términos estadísticos,
se trata de un balance de varianza y sesgo.


